{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection in OpenCV -- A 15 Minute Tutorial\n",
    "\n",
    "The website used for this tutorial is [here](https://www.sicara.ai/blog/2019-03-12-edge-detection-in-opencv).\n",
    "\n",
    "The link to the video used is [here](http://s000.tinyupload.com/?file_id=68020491182895316726)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Up and Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loads and displays a video.\n",
    "\"\"\"\n",
    "\n",
    "# Importing OpenCV\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture('cafe.mp4')\n",
    " \n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "    \n",
    "# Read the video\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        # Converting the image to grayscale.\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Frame', gray)\n",
    "\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    " \n",
    "    # Break the loop\n",
    "    else: \n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "print(\"here\")\n",
    " \n",
    "# Closes all the frames\n",
    "# cv2.destroyAllWindows(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still objects edge detection\n",
    "#### The Canny Filter\n",
    "\n",
    "The general criteria for edge detection include:\n",
    "\n",
    "1. Detection of edge with low error rate, which means that the detection should accurately catch as many edges shown in the image as possible\n",
    "2. The edge point detected from the operator should accurately localize on the center of the edge.\n",
    "3. A given edge in the image should only be marked once, and where possible, image noise should not create false edges.\n",
    "\n",
    "The Process of Canny edge detection algorithm can be broken down to 5 different steps:\n",
    "\n",
    "1. Apply Gaussian filter to smooth the image in order to remove the noise\n",
    "2. Find the intensity gradients of the image\n",
    "3. Apply non-maximum suppression to get rid of spurious response to edge detection\n",
    "4. Apply double threshold to determine potential edges\n",
    "5. Track edge by hysteresis: Finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges.  The hysteresis enables the selection of lines of adjacent pixels contrasting with their neighbors.\n",
    "\n",
    "![The successive steps of the Canny filter.](img/CannyFilter.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'canny_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a0777d7ea6fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Display the resulting frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanny_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'canny_images' is not defined"
     ]
    }
   ],
   "source": [
    "# Converting the image to grayscale.\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Using the Canny filter to get contours\n",
    "edges = cv2.Canny(gray, 20, 30)\n",
    "# Using the Canny filter with different parameters\n",
    "edges_high_thresh = cv2.Canny(gray, 60, 120)\n",
    "# Stacking the images to print them together\n",
    "# For comparison\n",
    "images = np.hstack((gray, edges, edges_high_thresh))\n",
    "\n",
    "# Display the resulting frame\n",
    "cv2.imshow('Frame', canny_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
